# -*- coding: utf-8 -*-
"""openAQML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wF8_ItTf4mTvy3iYdQ3Ckvs66RWVv3U7
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/Datasets/Level 2 OpenAQ Air Quality/openAQFeatureEngineered.csv')
df.head()

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler

# creating target and features
y = df['value']
X = df.drop(columns=['value', 'source name', 'country label', 'location'])

catCols = ["pollutant", "unit", "country code", "season", "weekday", "is weekend"]
numCols = ['latitude', 'longitude', 'year', 'month', 'day', 'hour', 'weekday', 'val lat',
           'val lon']

preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numCols),
    ('cat', OneHotEncoder(handle_unknown='ignore'), catCols),
])

# splitting data
train = df[df.year < 2024]
test = df[df.year == 2024]

xTrain = train.drop(columns=['value', 'source name', 'country label', 'location'])
yTrain = train['value']
xTest = test.drop(columns=['value', 'source name', 'country label', 'location'])
yTest = test['value']

# training regression models
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import Ridge
from sklearn.svm import SVR
from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error

models = {
    'Random Forest': RandomForestRegressor(n_estimators=100),
    'Ridge': Ridge(alpha=1.0, random_state=42),
    'SVM': SVR(kernel='linear')
}

results = {}
bestScore = -np.inf
bestModel = None
bestPipeline = None

for name, model in models.items():
  pipeline = Pipeline(steps=[('preprocessor', preprocessor),
   ('regressor', model)])
  pipeline.fit(xTrain, yTrain)
  preds = pipeline.predict(xTest)
  mae = mean_absolute_error(yTest, preds)
  r2Score = r2_score(yTest, preds)
  maep = mean_absolute_percentage_error(yTest, preds)
  results[name] = {'MAE: ': mae, 'R² score: ': r2Score, 'MAEP: ': maep}
  print(f'{name}: MAE: {mae} | R²: {r2Score} | MAEP: {maep}')

  # plotting residuals
  residuals = yTest - preds
  plt.figure(figsize=(8, 5))
  plt.scatter(preds, residuals, edgecolor='black', color='#2780F5', alpha=0.6)
  plt.xlabel('Predicted values')
  plt.ylabel('Residuals')
  plt.title(f'Residual Plot: {name}')
  plt.axhline(y=0, color='#F54927', lw=1.2, linestyle='--')
  plt.tight_layout()
  plt.show()

  if r2Score > bestScore:
    bestScore = r2Score
    bestModel = model
    bestPipeline = pipeline

# plotting metrics (MAE, R² score and MAEP)
maes, r2Scores, maeps = [], [], []
mlMetrics = [metric for metric in list(results.keys())]

for key, metricValues in results.items():
    for metricKey, metricValue in metricValues.items():
        if metricKey == 'MAE: ':
            maes.append(metricValue)
        elif metricKey == 'R² score: ':
            r2Scores.append(metricValue)
        else:
            maeps.append(metricValue)

fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 5),
                         constrained_layout=True)

axes[0].bar(mlMetrics, maes, ec='black', color='#F5BB27', label='MAE')
axes[0].legend(loc="best")
axes[0].grid(alpha=0.2)

axes[1].bar(mlMetrics, r2Scores, ec='black', color='#B0F527', label='R² Score')
axes[1].legend(loc="best")
axes[1].grid(alpha=0.2)

axes[2].bar(mlMetrics, maeps, ec='black', color='#DD5DE3', label='MAEP')
axes[2].set_yscale('log')
axes[2].legend(loc="best")
axes[2].grid(alpha=0.2)

# best niodel
print(bestModel)

# saving the best model
import joblib
joblib.dump(bestModel, filename='/content/drive/MyDrive/Datasets/Level 2 OpenAQ Air Quality/bestModel.pkl')

"""### Conclusions

-Several numerical (e.g., latitude, longitude, year, hour) and categorical (e.g., pollutant, country, season) features were used to predict air pollution levels (“value”) using three regression models: Random Forest, Ridge Regression and Support Vector Machine (SVR).

-The models were evaluated using R², Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE).

Overall model performance was modest:

-Ridge Regression achieved the best performance with an R² of 0.32, indicating that it explains roughly 32% of the variance in pollution values.

-Support Vector Regression performed slightly worse (R² ≈ 0.16).

-Random Forest produced a negative R², suggesting that it performed worse than a simple mean-based baseline — possibly due to overfitting, lack of hyperparameter tuning or issues with feature scaling.

Residual analysis showed that prediction errors were widely scattered, indicating that the current feature set and models may not capture key relationships driving pollution levels.

These results suggest that feature engineering (e.g., adding weather, time-lagged or regional indicators) and hyperparameter tuning could substantially improve performance in future iterations.
"""