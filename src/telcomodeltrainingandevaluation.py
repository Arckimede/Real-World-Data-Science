# -*- coding: utf-8 -*-
"""telcoModelTrainingAndEvaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c6HvrixsmSKlDgIutBlreGXqEEnRRfca
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

df = pd.read_csv('/content/drive/MyDrive/Datasets/CSV and Excel files/telcoCustomerChurnClean.csv')
df.head()

# preparing data
X = df.drop('Churn', axis=1)
y = df['Churn'].map({'Yes': 1, 'No': 0}) # encoding target

xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# preprocessing and pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

numFeatures = ['Tenure', 'MonthlyCharges', 'TotalCharges'] # numeric
catFeatures = [col for col in X.columns if col not in numFeatures] # categorical

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numFeatures),
        ('cat', OneHotEncoder(handle_unknown='ignore'), catFeatures)
    ]
)

# model selection
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'SVM': SVC(probability=True)
}

# Training and Hyperparameter Tuning
from sklearn.model_selection import GridSearchCV

pipeline = Pipeline([
 ('preprocessor', preprocessor),
 ('classifier', RandomForestClassifier(random_state=42))
])

paramGrid = {
    'classifier__n_estimators': [100, 200],
    'classifier__max_depth': [5, 10, None],
    'classifier__min_samples_split': [2, 5],
}

gridSearch = GridSearchCV(pipeline, paramGrid, cv=5, scoring='roc_auc')
gridSearch.fit(xTrain, yTrain)

print(gridSearch.best_params_)
print(gridSearch.best_score_)

# evaluation: using multiple metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

yPred = gridSearch.predict(xTest)
yProba = gridSearch.predict_proba(xTest)[:, 1]

print(f'Accuracy: {accuracy_score(yTest, yPred)}')
print(f'Precision: {precision_score(yTest, yPred)}')
print(f'Recall: {recall_score(yTest, yPred)}')
print(f'ROC AUC: {roc_auc_score(yTest, yProba)}')

cm = confusion_matrix(yTest, yPred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# saving for reproducibility
import joblib
joblib.dump(gridSearch.best_estimator_, '/content/drive/MyDrive/Datasets/CSV and Excel files/bestModel.pkl')